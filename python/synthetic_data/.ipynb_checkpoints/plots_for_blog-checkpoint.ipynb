{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb6d25c-ff78-444f-8fae-b6971ae09a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Choose your projection method:\n",
      "  'pca'    - Principal Component Analysis (linear)\n",
      "  'kpca'   - Kernel PCA (non-linear, various kernels)\n",
      "            Kernels: 'rbf', 'poly', 'sigmoid', 'cosine', 'linear'\n",
      "  'tsne'   - t-SNE (non-linear, preserves local structure)\n",
      "  'umap'   - UMAP (non-linear, fast, preserves global structure)\n",
      "  'isomap' - Isomap (non-linear manifold learning)\n",
      "  'mds'    - Multidimensional Scaling (distance-preserving)\n",
      "============================================================\n",
      "Loading MNIST dataset...\n",
      "Found 7877 samples of digit 1\n",
      "Sampling 5000 random samples for efficiency...\n",
      "Performing  projection...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown method: . Choose from 'pca', 'kpca', 'tsne', 'umap', 'isomap', or 'mds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 312\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# Example: Run with PCA (original method)\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# reducer, X_proj, X_data = visualize_mnist_projections(digit='3', n_images=12, method='pca')\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m \n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# Example: Run with UMAP (from original)\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m reducer, X_proj, X_data \u001b[38;5;241m=\u001b[39m visualize_mnist_projections(digit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, n_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 129\u001b[0m, in \u001b[0;36mvisualize_mnist_projections\u001b[0;34m(digit, n_images, method, n_samples_max, kernel, gamma)\u001b[0m\n\u001b[1;32m    126\u001b[0m     method_display \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMDS\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Choose from \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpca\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkpca\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsne\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mumap\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124misomap\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmds\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Create subplots with Plotly\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_variance_plot:\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown method: . Choose from 'pca', 'kpca', 'tsne', 'umap', 'isomap', or 'mds'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import TSNE, Isomap, MDS\n",
    "from sklearn.datasets import fetch_openml\n",
    "import umap\n",
    "\n",
    "def visualize_mnist_projections(digit='3', n_images=10, method='pca', n_samples_max=5000, kernel='rbf', gamma=None):\n",
    "    \"\"\"\n",
    "    Projects MNIST digit to 3D using various dimensionality reduction methods.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    digit : str\n",
    "        Which digit to visualize (0-9)\n",
    "    n_images : int\n",
    "        Number of sample images to display on the 3D plot\n",
    "    method : str\n",
    "        Projection method: 'pca', 'kpca', 'tsne', 'umap', 'isomap', or 'mds'\n",
    "    n_samples_max : int\n",
    "        Maximum number of samples to use (for computational efficiency with non-linear methods)\n",
    "    kernel : str\n",
    "        Kernel for KernelPCA: 'rbf', 'poly', 'sigmoid', 'cosine', 'linear'\n",
    "    gamma : float or None\n",
    "        Kernel coefficient for rbf, poly and sigmoid kernels. If None, uses 1/n_features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load MNIST dataset\n",
    "    print(\"Loading MNIST dataset...\")\n",
    "    mnist = fetch_openml('mnist_784', version=1, parser='auto')\n",
    "    X, y = mnist.data, mnist.target\n",
    "    \n",
    "    # Convert to numpy arrays and filter for specific digit\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Filter only specified digit\n",
    "    mask = y == digit\n",
    "    X_digit = X[mask]\n",
    "    \n",
    "    print(f\"Found {len(X_digit)} samples of digit {digit}\")\n",
    "    \n",
    "    # Limit samples for computational efficiency\n",
    "    if len(X_digit) > n_samples_max:\n",
    "        print(f\"Sampling {n_samples_max} random samples for efficiency...\")\n",
    "        sample_indices = np.random.choice(len(X_digit), n_samples_max, replace=False)\n",
    "        X_digit = X_digit[sample_indices]\n",
    "    \n",
    "    # Normalize the data\n",
    "    X_digit = X_digit / 255.0\n",
    "    \n",
    "    # Perform dimensionality reduction\n",
    "    print(f\"Performing {method.upper()} projection...\")\n",
    "    \n",
    "    if method.lower() == 'pca':\n",
    "        reducer = PCA(n_components=100)\n",
    "        X_reduced_full = reducer.fit_transform(X_digit)\n",
    "        X_projected = X_reduced_full[:, :3]\n",
    "        \n",
    "        # Calculate variance info\n",
    "        variance_3d = np.sum(reducer.explained_variance_ratio_[:3])\n",
    "        variance_info = f\"{variance_3d:.1%} variance explained\"\n",
    "        \n",
    "        # For variance plot\n",
    "        cumulative_variance = np.cumsum(reducer.explained_variance_ratio_)\n",
    "        show_variance_plot = True\n",
    "        method_display = 'PCA'\n",
    "        \n",
    "    elif method.lower() == 'kpca':\n",
    "        # Kernel PCA with specified kernel\n",
    "        # Limit samples further for computational efficiency\n",
    "        if len(X_digit) > 2000:\n",
    "            print(f\"Kernel PCA is computationally expensive. Using only 2000 samples...\")\n",
    "            X_digit = X_digit[:2000]\n",
    "        \n",
    "        kpca_params = {\n",
    "            'n_components': 3,\n",
    "            'kernel': kernel,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "        # Set gamma if provided, otherwise use default\n",
    "        if gamma is not None:\n",
    "            kpca_params['gamma'] = gamma\n",
    "        \n",
    "        reducer = KernelPCA(**kpca_params)\n",
    "        X_projected = reducer.fit_transform(X_digit)\n",
    "        \n",
    "        variance_info = f\"{kernel.upper()} kernel\"\n",
    "        show_variance_plot = False\n",
    "        method_display = f'Kernel PCA ({kernel})'\n",
    "        \n",
    "    elif method.lower() == 'tsne':\n",
    "        reducer = TSNE(n_components=3, random_state=42, perplexity=30, n_iter=1000)\n",
    "        X_projected = reducer.fit_transform(X_digit)\n",
    "        variance_info = \"Non-linear projection\"\n",
    "        show_variance_plot = False\n",
    "        method_display = 't-SNE'\n",
    "        \n",
    "    elif method.lower() == 'umap':\n",
    "        reducer = umap.UMAP(n_components=3, random_state=42, n_neighbors=15, min_dist=0.1)\n",
    "        X_projected = reducer.fit_transform(X_digit)\n",
    "        variance_info = \"Non-linear projection\"\n",
    "        show_variance_plot = False\n",
    "        method_display = 'UMAP'\n",
    "        \n",
    "    elif method.lower() == 'isomap':\n",
    "        reducer = Isomap(n_components=3, n_neighbors=10)\n",
    "        X_projected = reducer.fit_transform(X_digit)\n",
    "        variance_info = \"Non-linear manifold projection\"\n",
    "        show_variance_plot = False\n",
    "        method_display = 'Isomap'\n",
    "        \n",
    "    elif method.lower() == 'mds':\n",
    "        # MDS is computationally expensive, so we limit it further\n",
    "        if len(X_digit) > 2000:\n",
    "            print(\"MDS is computationally expensive. Using only 2000 samples...\")\n",
    "            X_digit = X_digit[:2000]\n",
    "        reducer = MDS(n_components=3, random_state=42)\n",
    "        X_projected = reducer.fit_transform(X_digit)\n",
    "        variance_info = \"Distance-preserving projection\"\n",
    "        show_variance_plot = False\n",
    "        method_display = 'MDS'\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}. Choose from 'pca', 'kpca', 'tsne', 'umap', 'isomap', or 'mds'\")\n",
    "    \n",
    "    # Create subplots with Plotly\n",
    "    if show_variance_plot:\n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            column_widths=[0.4, 0.6],\n",
    "            subplot_titles=('Cumulative Explained Variance', \n",
    "                           f'3D {method_display} Projection of MNIST Digit {digit}<br>({len(X_digit)} samples, {variance_info})'),\n",
    "            specs=[[{'type': 'xy'}, {'type': 'scatter3d'}]]\n",
    "        )\n",
    "        \n",
    "        # Plot 1: Cumulative explained variance (PCA only)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=list(range(1, min(101, len(cumulative_variance) + 1))),\n",
    "                y=cumulative_variance[:100],\n",
    "                mode='lines',\n",
    "                name='Cumulative Variance',\n",
    "                line=dict(color='blue', width=2)\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Add reference lines\n",
    "        fig.add_hline(y=0.95, line_dash=\"dash\", line_color=\"red\", \n",
    "                      annotation_text=\"95%\", row=1, col=1)\n",
    "        fig.add_hline(y=0.90, line_dash=\"dash\", line_color=\"orange\", \n",
    "                      annotation_text=\"90%\", row=1, col=1)\n",
    "        \n",
    "        # Update variance plot layout\n",
    "        fig.update_xaxes(title_text=\"Number of Components\", row=1, col=1, range=[0, 100])\n",
    "        fig.update_yaxes(title_text=\"Cumulative Explained Variance\", row=1, col=1)\n",
    "        \n",
    "        col_idx = 2\n",
    "    else:\n",
    "        fig = go.Figure()\n",
    "        col_idx = None\n",
    "    \n",
    "    # Select random samples to display as images\n",
    "    n_samples = min(n_images, len(X_digit))\n",
    "    random_indices = np.random.choice(len(X_digit), n_samples, replace=False)\n",
    "    \n",
    "    # Create axis labels\n",
    "    axis_prefix = method_display.replace(' ', '_').replace('(', '').replace(')', '').upper()\n",
    "    \n",
    "    # Plot: 3D projection - all points\n",
    "    scatter_all = go.Scatter3d(\n",
    "        x=X_projected[:, 0],\n",
    "        y=X_projected[:, 1],\n",
    "        z=X_projected[:, 2],\n",
    "        mode='markers',\n",
    "        name=f'All digit {digit}s',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color='blue',\n",
    "            opacity=0.3\n",
    "        ),\n",
    "        hovertemplate=f'{axis_prefix}1: %{{x:.2f}}<br>{axis_prefix}2: %{{y:.2f}}<br>{axis_prefix}3: %{{z:.2f}}<extra></extra>'\n",
    "    )\n",
    "    \n",
    "    # Highlight selected points\n",
    "    scatter_highlight = go.Scatter3d(\n",
    "        x=X_projected[random_indices, 0],\n",
    "        y=X_projected[random_indices, 1],\n",
    "        z=X_projected[random_indices, 2],\n",
    "        mode='markers',\n",
    "        name=f'{n_samples} highlighted samples',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color='red',\n",
    "            opacity=0.9,\n",
    "            line=dict(color='black', width=2)\n",
    "        ),\n",
    "        hovertemplate=f'Sample %{{text}}<br>{axis_prefix}1: %{{x:.2f}}<br>{axis_prefix}2: %{{y:.2f}}<br>{axis_prefix}3: %{{z:.2f}}<extra></extra>',\n",
    "        text=[f'{i+1}' for i in range(n_samples)]\n",
    "    )\n",
    "    \n",
    "    if show_variance_plot:\n",
    "        fig.add_trace(scatter_all, row=1, col=2)\n",
    "        fig.add_trace(scatter_highlight, row=1, col=2)\n",
    "        \n",
    "        # Update 3D plot layout\n",
    "        fig.update_scenes(\n",
    "            xaxis_title=f'{axis_prefix}1',\n",
    "            yaxis_title=f'{axis_prefix}2',\n",
    "            zaxis_title=f'{axis_prefix}3',\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        title_text = f\"MNIST Digit {digit} - {method_display} Analysis\"\n",
    "    else:\n",
    "        fig.add_trace(scatter_all)\n",
    "        fig.add_trace(scatter_highlight)\n",
    "        \n",
    "        # Update 3D plot layout\n",
    "        fig.update_scenes(\n",
    "            xaxis_title=f'{axis_prefix}1',\n",
    "            yaxis_title=f'{axis_prefix}2',\n",
    "            zaxis_title=f'{axis_prefix}3'\n",
    "        )\n",
    "        \n",
    "        title_text = f\"MNIST Digit {digit} - {method_display} 3D Projection<br>({len(X_digit)} samples, {variance_info})\"\n",
    "    \n",
    "    # Update overall layout\n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        showlegend=True,\n",
    "        title_text=title_text,\n",
    "        title_font_size=16\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Create a matplotlib figure for the sample images\n",
    "    fig2, axes = plt.subplots(2, (n_samples + 1) // 2, figsize=(15, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, img_idx in enumerate(random_indices):\n",
    "        img = X_digit[img_idx].reshape(28, 28)\n",
    "        axes[idx].imshow(img, cmap='gray')\n",
    "        axes[idx].set_title(f'Sample {idx+1}\\n{axis_prefix}1:{X_projected[img_idx, 0]:.1f}', fontsize=9)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Hide extra subplots\n",
    "    for idx in range(len(random_indices), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Sample Images from 3D {method_display} Plot', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\n--- {method_display} Statistics ---\")\n",
    "    print(f\"Total samples: {len(X_digit)}\")\n",
    "    print(f\"Original dimensions: {X_digit.shape[1]}\")\n",
    "    \n",
    "    if method.lower() == 'pca':\n",
    "        print(f\"Variance explained by PC1: {reducer.explained_variance_ratio_[0]:.2%}\")\n",
    "        print(f\"Variance explained by PC2: {reducer.explained_variance_ratio_[1]:.2%}\")\n",
    "        print(f\"Variance explained by PC3: {reducer.explained_variance_ratio_[2]:.2%}\")\n",
    "        print(f\"Total variance explained by 3D: {variance_3d:.2%}\")\n",
    "    elif method.lower() == 'kpca':\n",
    "        print(f\"Kernel: {kernel}\")\n",
    "        if gamma is not None:\n",
    "            print(f\"Gamma: {gamma}\")\n",
    "        print(f\"Note: Kernel PCA doesn't have variance explained metrics\")\n",
    "    else:\n",
    "        print(f\"Projection type: {variance_info}\")\n",
    "        print(f\"Note: Non-linear methods don't have variance explained metrics\")\n",
    "    \n",
    "    return reducer, X_projected, X_digit\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Choose your projection method:\")\n",
    "    print(\"  'pca'    - Principal Component Analysis (linear)\")\n",
    "    print(\"  'kpca'   - Kernel PCA (non-linear, various kernels)\")\n",
    "    print(\"            Kernels: 'rbf', 'poly', 'sigmoid', 'cosine', 'linear'\")\n",
    "    print(\"  'tsne'   - t-SNE (non-linear, preserves local structure)\")\n",
    "    print(\"  'umap'   - UMAP (non-linear, fast, preserves global structure)\")\n",
    "    print(\"  'isomap' - Isomap (non-linear manifold learning)\")\n",
    "    print(\"  'mds'    - Multidimensional Scaling (distance-preserving)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Example: Run with PCA (original method)\n",
    "    # reducer, X_proj, X_data = visualize_mnist_projections(digit='3', n_images=12, method='pca')\n",
    "    \n",
    "    # Example: Run with Kernel PCA - RBF kernel\n",
    "    #reducer, X_proj, X_data = visualize_mnist_projections(digit='1', n_images=1, method='kpca', kernel='rbf')\n",
    "    \n",
    "    # Example: Run with Kernel PCA - Polynomial kernel\n",
    "    #reducer, X_proj, X_data = visualize_mnist_projections(digit='1', n_images=12, method='kpca', kernel='poly')\n",
    "    \n",
    "    # Example: Run with Kernel PCA - Sigmoid kernel\n",
    "    #reducer, X_proj, X_data = visualize_mnist_projections(digit='7', n_images=12, method='kpca', kernel='sigmoid')\n",
    "    \n",
    "    # Example: Run with Kernel PCA - Cosine kernel\n",
    "    #reducer, X_proj, X_data = visualize_mnist_projections(digit='5', n_images=12, method='kpca', kernel='cosine')\n",
    "    \n",
    "    # Example: Run with UMAP (from original)\n",
    "    reducer, X_proj, X_data = visualize_mnist_projections(digit='1', n_images=1, method='')\n",
    "    \n",
    "    # Compare different kernels for the same digit:\n",
    "    # for kernel in ['rbf', 'poly', 'sigmoid', 'cosine']:\n",
    "    #     print(f\"\\n\\n{'='*60}\\nTesting {kernel.upper()} kernel\\n{'='*60}\")\n",
    "    #     reducer, X_proj, X_data = visualize_mnist_projections(\n",
    "    #         digit='3', n_images=8, method='kpca', kernel=kernel, n_samples_max=2000\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b8676-6695-4e50-83a6-7ba061778bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def image_to_base64_png(image_array):\n",
    "    \"\"\"\n",
    "    Convert a 28x28 numpy array to a base64-encoded PNG data URI.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image_array : np.array\n",
    "        28x28 grayscale image array (values 0-1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : base64-encoded PNG data URI\n",
    "    \"\"\"\n",
    "    # Convert to 0-255 range\n",
    "    img_data = (image_array * 255).astype(np.uint8)\n",
    "    \n",
    "    # Create PIL Image\n",
    "    img = Image.fromarray(img_data, mode='L')\n",
    "    \n",
    "    # Save to bytes buffer as PNG\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format='PNG')\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # Encode to base64\n",
    "    img_base64 = base64.b64encode(buffer.read()).decode('utf-8')\n",
    "    \n",
    "    # Return as data URI\n",
    "    return f\"data:image/png;base64,{img_base64}\"\n",
    "\n",
    "\n",
    "def generate_projection_json(digit='3', method='pca', n_samples_output=100, n_samples_max=5000, output_file=None):\n",
    "    \"\"\"\n",
    "    Generate JSON file with 3D projection coordinates and base64-encoded images.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    digit : str\n",
    "        Which digit to visualize (0-9)\n",
    "    method : str\n",
    "        Projection method: 'pca', 'tsne', 'umap', 'isomap', or 'mds'\n",
    "    n_samples_output : int\n",
    "        Number of samples to include in the JSON output\n",
    "    n_samples_max : int\n",
    "        Maximum number of samples to use for projection computation\n",
    "    output_file : str or None\n",
    "        Output JSON filename. If None, returns the data without saving.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list : List of dictionaries with id, x, y, z, and image data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load MNIST dataset\n",
    "    print(\"Loading MNIST dataset...\")\n",
    "    mnist = fetch_openml('mnist_784', version=1, parser='auto')\n",
    "    X, y = mnist.data, mnist.target\n",
    "    \n",
    "    # Convert to numpy arrays and filter for specific digit\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Filter only specified digit\n",
    "    mask = y == digit\n",
    "    X_digit = X[mask]\n",
    "    \n",
    "    print(f\"Found {len(X_digit)} samples of digit {digit}\")\n",
    "    \n",
    "    # Limit samples for computational efficiency\n",
    "    if len(X_digit) > n_samples_max:\n",
    "        print(f\"Sampling {n_samples_max} random samples for efficiency...\")\n",
    "        sample_indices = np.random.choice(len(X_digit), n_samples_max, replace=False)\n",
    "        X_digit = X_digit[sample_indices]\n",
    "    \n",
    "    # Normalize the data\n",
    "    X_digit_normalized = X_digit / 255.0\n",
    "    \n",
    "    # Perform dimensionality reduction\n",
    "    print(f\"Performing {method.upper()} projection...\")\n",
    "    \n",
    "    if method.lower() == 'pca':\n",
    "        reducer = PCA(n_components=3)\n",
    "        X_projected = reducer.fit_transform(X_digit_normalized)\n",
    "        \n",
    "    elif method.lower() == 'tsne':\n",
    "        reducer = TSNE(n_components=3, random_state=42, perplexity=30, n_iter=1000)\n",
    "        X_projected = reducer.fit_transform(X_digit_normalized)\n",
    "        \n",
    "    elif method.lower() == 'umap':\n",
    "        reducer = umap.UMAP(n_components=3, random_state=42, n_neighbors=15, min_dist=0.1)\n",
    "        X_projected = reducer.fit_transform(X_digit_normalized)\n",
    "        \n",
    "    elif method.lower() == 'isomap':\n",
    "        reducer = Isomap(n_components=3, n_neighbors=10)\n",
    "        X_projected = reducer.fit_transform(X_digit_normalized)\n",
    "        \n",
    "    elif method.lower() == 'mds':\n",
    "        if len(X_digit_normalized) > 2000:\n",
    "            print(\"MDS is computationally expensive. Using only 2000 samples...\")\n",
    "            X_digit = X_digit[:2000]\n",
    "            X_digit_normalized = X_digit_normalized[:2000]\n",
    "        reducer = MDS(n_components=3, random_state=42)\n",
    "        X_projected = reducer.fit_transform(X_digit_normalized)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}. Choose from 'pca', 'tsne', 'umap', 'isomap', or 'mds'\")\n",
    "    \n",
    "    # Select samples for output\n",
    "    n_output = min(n_samples_output, len(X_digit))\n",
    "    output_indices = np.random.choice(len(X_digit), n_output, replace=False)\n",
    "    \n",
    "    print(f\"Generating JSON with {n_output} samples...\")\n",
    "    \n",
    "    # Create JSON data\n",
    "    json_data = []\n",
    "    for idx, sample_idx in enumerate(output_indices):\n",
    "        # Get image and reshape\n",
    "        img = X_digit_normalized[sample_idx].reshape(28, 28)\n",
    "        \n",
    "        # Convert to base64\n",
    "        img_base64 = image_to_base64_png(img)\n",
    "        \n",
    "        # Create entry\n",
    "        entry = {\n",
    "            \"id\": int(idx),\n",
    "            \"x\": float(X_projected[sample_idx, 0]),\n",
    "            \"y\": float(X_projected[sample_idx, 1]),\n",
    "            \"z\": float(X_projected[sample_idx, 2]),\n",
    "            \"image\": img_base64\n",
    "        }\n",
    "        json_data.append(entry)\n",
    "        \n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"  Processed {idx + 1}/{n_output} images...\")\n",
    "    \n",
    "    # Save to file if specified\n",
    "    if output_file:\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(json_data, f, indent=2)\n",
    "        print(f\"\\nJSON saved to: {output_file}\")\n",
    "        print(f\"File contains {len(json_data)} samples\")\n",
    "    \n",
    "    print(f\"\\n--- Generation Complete ---\")\n",
    "    print(f\"Method: {method.upper()}\")\n",
    "    print(f\"Digit: {digit}\")\n",
    "    print(f\"Total entries: {len(json_data)}\")\n",
    "    \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bed945-e07c-4ef2-b1b9-ebf6785ec2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_projection_json(\n",
    "    digit='1',\n",
    "    method='pca',\n",
    "    n_samples_output=5000,\n",
    "    output_file='manifoldData.json'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
